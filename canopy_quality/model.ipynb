{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bff69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in necessary packages\n",
    "import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "from osgeo import gdal\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import pandas as pd\n",
    "\n",
    "from torchinfo import summary\n",
    "import gc\n",
    "from torch.autograd import Variable\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchmetrics import JaccardIndex\n",
    "from torchmetrics.classification import BinaryJaccardIndex\n",
    "from torchmetrics import MeanAbsoluteError\n",
    "from torchmetrics.functional import dice_score\n",
    "from scipy.ndimage import convolve\n",
    "from tqdm.auto import tqdm # progress bar\n",
    "from timeit import default_timer as timer\n",
    "def print_train_time(start:float,\n",
    "                    end:float,\n",
    "                    device: torch.device= None):\n",
    "    total_time=end-start\n",
    "    print(f\"Train time on {device} : {total_time:.3f} seconds\")\n",
    "    return total_time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a71874",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804e1a10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a705132",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create Dataloaders using the file paths ###\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Create two DataLoaders, one for training and one for test\n",
    "class allbands_dataset_train(Dataset):\n",
    "    def __init__(self,filelist_train, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            filelist (string): List with all of the file paths\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.transform = transform\n",
    "        self.filelist = filelist_train           \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filelist)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()    \n",
    "            \n",
    "        # Generate data\n",
    "        dataset = np.load(self.filelist[idx])\n",
    "        \n",
    "        # X\n",
    "        X=dataset[:14] # separate out the band values\n",
    "\n",
    "        # canopy_height,tree/not tree,ndvi\n",
    "        out_tree_height = dataset[14]         \n",
    "        out_tree_mask = dataset[15]\n",
    "        \n",
    "        preds=[out_tree_height, out_tree_mask]\n",
    "        \n",
    "        return [X,preds]\n",
    "    \n",
    "class allbands_dataset_test(Dataset):\n",
    "    def __init__(self,filelist_test, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            filelist (string): List with all of the file paths\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.transform = transform\n",
    "        self.filelist = filelist_test           \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filelist)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()    \n",
    "        # Generate data\n",
    "        dataset = np.load(self.filelist[idx])\n",
    "        \n",
    "        # X\n",
    "        X=dataset[:14] # separate out the band values\n",
    "\n",
    "        # canopy_height,tree/not tree,ndvi\n",
    "        out_tree_height = dataset[14]         \n",
    "        out_tree_mask = dataset[15]\n",
    "        \n",
    "        preds=[out_tree_height, out_tree_mask]\n",
    "        \n",
    "        return [X,preds]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10875c25",
   "metadata": {},
   "source": [
    "# Muti-task Manual Loss- Not Shared Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7677cb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a version with shared encoding paths but different encoding paths\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "def defineUNetModel_partiallyshared():\n",
    "    def double_conv0(in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, padding=\"same\"),\n",
    "            nn.InstanceNorm2d(out_channels),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, padding=\"same\"),\n",
    "            nn.InstanceNorm2d(out_channels),\n",
    "            nn.LeakyReLU(inplace=True)\n",
    "        )  \n",
    "    def double_conv(in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
    "            nn.LeakyReLU(inplace=True)\n",
    "        )\n",
    "    \n",
    "    class UNet(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "\n",
    "            self.dconv_down1 = double_conv0(14, 32)\n",
    "            self.dconv_down2 = double_conv(32, 64)\n",
    "            self.dconv_down3 = double_conv(64, 128)\n",
    "            self.dconv_down4 = nn.Sequential(\n",
    "                nn.Conv2d(128, 256, 3, padding=1),\n",
    "                nn.LeakyReLU(inplace=True),\n",
    "                nn.Dropout(p=0.2),\n",
    "                nn.Conv2d(256, 256, 3, padding=1),\n",
    "                nn.LeakyReLU(inplace=True))\n",
    "\n",
    "            self.maxpool = nn.MaxPool2d(2)\n",
    "            self.maxpool3 = nn.MaxPool2d(3)\n",
    "            \n",
    "            self.upsample1a = nn.ConvTranspose2d(256, 128, 3, stride=3, padding=0)\n",
    "            self.upsample1b = nn.ConvTranspose2d(256, 128, 3, stride=3, padding=0)\n",
    "            self.upsample1c = nn.ConvTranspose2d(256, 128, 3, stride=3, padding=0)\n",
    "            \n",
    "            self.upsample2a = nn.ConvTranspose2d(128, 64, 2, stride=2, padding=0)\n",
    "            self.upsample2b = nn.ConvTranspose2d(128, 64, 2, stride=2, padding=0)\n",
    "            self.upsample2c = nn.ConvTranspose2d(128, 64, 2, stride=2, padding=0)\n",
    "            \n",
    "            self.upsample3a = nn.ConvTranspose2d(64, 32, 2, stride=2, padding=0)\n",
    "            self.upsample3b = nn.ConvTranspose2d(64, 32, 2, stride=2, padding=0)\n",
    "            self.upsample3c = nn.ConvTranspose2d(64, 32, 2, stride=2, padding=0)\n",
    "            \n",
    "            \n",
    "            self.dconv_up3a = double_conv(128+128, 128)\n",
    "            self.dconv_up3b = double_conv(128+128, 128)\n",
    "            self.dconv_up3c = double_conv(128+128, 128)\n",
    "            \n",
    "            self.dconv_up2a = double_conv(64 + 64, 64)\n",
    "            self.dconv_up2b = double_conv(64 + 64, 64)\n",
    "            self.dconv_up2c = double_conv(64 + 64, 64)\n",
    "            \n",
    "            self.dconv_up1a = double_conv(32 + 32, 32)\n",
    "            self.dconv_up1b = double_conv(32 + 32, 32)\n",
    "            self.dconv_up1c = double_conv(32 + 32, 32)\n",
    "           # self.dconv_up1 = double_conv(128 + 64, 64)\n",
    "\n",
    "            self.conv_lasta = nn.Conv2d(32, 1, 1)\n",
    "            self.conv_lastb = nn.Conv2d(32, 1, 1)\n",
    "            self.conv_lastc = nn.Conv2d(32, 1, 1)\n",
    "                    \n",
    "            self.linear = nn.MaxPool2d(2)\n",
    "            self.sigmoid = nn.Sigmoid()\n",
    "        def forward(self, x):\n",
    "            conv1 = self.dconv_down1(x)\n",
    "            x = self.maxpool(conv1)\n",
    "\n",
    "            conv2 = self.dconv_down2(x)\n",
    "            x = self.maxpool(conv2)\n",
    "\n",
    "            conv3 = self.dconv_down3(x)\n",
    "            x = self.maxpool3(conv3)\n",
    "\n",
    "            encoder_end = self.dconv_down4(x)\n",
    "            #x = self.maxpool(conv4)\n",
    "            \n",
    "            # Now the model should split into three branches\n",
    "\n",
    "            # Tree Height\n",
    "            x1 = self.upsample1a(encoder_end)\n",
    "            x1 = torch.cat([x1, conv3], dim=1)\n",
    "            x1 = self.dconv_up3a(x1)\n",
    "\n",
    "            x1 = self.upsample2a(x1)\n",
    "            x1 = torch.cat([x1, conv2], dim=1)\n",
    "            x1 = self.dconv_up2a(x1)\n",
    "\n",
    "            x1 = self.upsample3a(x1)\n",
    "            x1 = torch.cat([x1, conv1], dim=1)\n",
    "            x1 = self.dconv_up1a(x1)\n",
    "            out_tree_height = self.conv_lasta(x1) # looks like i don't need any additional activation here for linear\n",
    "\n",
    "            # Tree Mask\n",
    "            x2 = self.upsample1b(encoder_end)\n",
    "            x2 = torch.cat([x2, conv3], dim=1)\n",
    "            x2 = self.dconv_up3b(x2)\n",
    "\n",
    "            x2 = self.upsample2b(x2)\n",
    "            x2 = torch.cat([x2, conv2], dim=1)\n",
    "            x2 = self.dconv_up2b(x2)\n",
    "\n",
    "            x2 = self.upsample3b(x2)\n",
    "            x2 = torch.cat([x2, conv1], dim=1)\n",
    "            x2 = self.dconv_up1b(x2)\n",
    "            out_tree_mask = self.sigmoid(self.conv_lastb(x2))            \n",
    "     \n",
    "            \n",
    "            return [out_tree_height, out_tree_mask]\n",
    "    model=UNet()\n",
    "    return model\n",
    "\n",
    "torch.manual_seed(42)\n",
    "unet_1 = defineUNetModel_partiallyshared().to(device)\n",
    "unet_1.load_state_dict(torch.load(\"models/pytorch_paper_final/pytorch_mtloss_partshared_manual.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7552fdcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0495341f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa338d12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da938476",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3f52f397",
   "metadata": {},
   "source": [
    "###############################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41ce497",
   "metadata": {},
   "source": [
    "# Run Inference on 2021 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a346c6d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759be313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get filepaths for inferences images\n",
    "inputPath=\"2021_predictions\" # 12972\n",
    "filelist = []\n",
    "\n",
    "# Load the images, and append them to a list.\n",
    "for filepath in os.listdir(inputPath):\n",
    "    if filepath.endswith((\".tif\")):\n",
    "    #print(filepath)\n",
    "        tempfile=inputPath+'/{0}'.format(filepath)\n",
    "        filelist.append(tempfile)\n",
    "\n",
    "len(filelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4f7773",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430f35c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# i need to get each tif, append the new raster layers, remove the bands i dont need anymore (maybe keep rgb), and then save\n",
    "inputPath=\"D:/final_data/2021_predictions/\"\n",
    "\n",
    "driver = gdal.GetDriverByName(\"GTiff\")\n",
    "driver.Register()\n",
    "i=0\n",
    "# Load the images, and append them to a list.\n",
    "for filepath in os.listdir(inputPath):\n",
    "    if filepath.endswith((\".tif\")):\n",
    "        print(filepath)\n",
    "        i=i+1\n",
    "        print(i)\n",
    "        images = []\n",
    "        dataset = gdal.Open(inputPath+'/{0}'.format(filepath))\n",
    "        gt = dataset.GetGeoTransform()\n",
    "        proj = dataset.GetProjection()\n",
    "        \n",
    "        image = dataset.ReadAsArray()  # Returned image is a NumPy array with shape (16, 60, 60) for example.\n",
    "        # predict values based on the two different models\n",
    "        images.append(image)\n",
    "        image = np.stack(images, axis= 0)\n",
    "        X=image[:,:14,:,:].copy() # separate out the band values\n",
    "        X[X  < .0000001] = 0\n",
    "        X = np.transpose(X, axes=[0, 2, 3, 1])\n",
    "        \n",
    "        # normalize values of the input data to 0,1\n",
    "        X = X/X.max(axis=(3),keepdims=True)\n",
    "        \n",
    "        X = np.transpose(X, axes=[0,3,1,2])\n",
    "        X= torch.from_numpy(X)\n",
    "        X= X.to(device)\n",
    "        X = Variable(X.float().cuda())\n",
    "        unet_1.eval()\n",
    "        with torch.inference_mode():\n",
    "            pred_tree_height, pred_tree_mask = unet_1(X)\n",
    "\n",
    "        pred_tree_mask = np.asarray(pred_tree_mask.squeeze().cpu())\n",
    "        pred_tree_mask[pred_tree_mask  >= .4] = 1\n",
    "        pred_tree_mask[pred_tree_mask  < .4 ] = 0\n",
    "        \n",
    "        pred_tree_height = np.asarray(pred_tree_height.squeeze().cpu())*650\n",
    "        pred_tree_height[pred_tree_height  < 0 ] = 0\n",
    "        \n",
    "        outcome_data=np.stack([pred_tree_height,pred_tree_mask])\n",
    "\n",
    "        \n",
    "        # save solution\n",
    "        save_raster1 = driver.Create('2021_predictions_results_theight'+'/{0}'.format(filepath), \n",
    "                                    xsize=240, ysize=240, bands = 1)\n",
    "\n",
    "        save_raster1.SetGeoTransform(gt)\n",
    "        save_raster1.SetProjection(proj) \n",
    "        \n",
    "        outband_1 = save_raster1.GetRasterBand(1)\n",
    "        outband_1.WriteArray(outcome_data[0].astype(np.float32))\n",
    "        outband_1.SetNoDataValue(np.nan)\n",
    "        outband_1.FlushCache()\n",
    "        #outband_1 = None\n",
    "        save_raster1 = None\n",
    "        \n",
    "        # save solution\n",
    "        save_raster2 = driver.Create('2021_predictions_results_tbinary'+'/{0}'.format(filepath), \n",
    "                                    xsize=240, ysize=240, bands = 1)\n",
    "\n",
    "        save_raster2.SetGeoTransform(gt)\n",
    "        save_raster2.SetProjection(proj) \n",
    "        \n",
    "        outband_1 = save_raster2.GetRasterBand(1)\n",
    "        outband_1.WriteArray(outcome_data[1].astype(np.float32))\n",
    "        outband_1.SetNoDataValue(np.nan)\n",
    "        outband_1.FlushCache()        \n",
    "\n",
    "        #outband_5 = None\n",
    "        \n",
    "        save_raster2 = None\n",
    "\n",
    "# CPU times: total: 15min 33s\n",
    "# Wall time: 52min 3s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
